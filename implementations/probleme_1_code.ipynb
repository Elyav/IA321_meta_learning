{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GCMoku2Em2_p"
      },
      "outputs": [],
      "source": [
        "#from purecmaes import fmin\n",
        "import torch\n",
        "from torchvision.datasets import CIFAR10,MNIST\n",
        "from torchvision.models import wide_resnet101_2, resnet18\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import ToTensor, Lambda, Compose\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ydbetdlKnU6u"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def extract_features(loader):\n",
        "    model = resnet18(pretrained=True).to('cuda')\n",
        "    outputs = []\n",
        "    def hook(module, input, output):\n",
        "        outputs.append(output)\n",
        "    model.avgpool.register_forward_hook(hook)\n",
        "    model.eval()\n",
        "    labels = []\n",
        "    features = []\n",
        "    for data in loader:\n",
        "        img, label = data\n",
        "        labels.append(label.cpu().detach().numpy())\n",
        "        _ = model(img.to('cuda'))\n",
        "        features.append(outputs[0].cpu())\n",
        "        outputs = []\n",
        "    features = torch.cat(features,0).squeeze().numpy()\n",
        "    labels = np.concatenate(labels)\n",
        "    return features, labels\n",
        "\n",
        "def get_data():\n",
        "    trf = Compose([ToTensor(), Lambda(lambda x: x.repeat(3, 1, 1)) ])\n",
        "    loader = DataLoader(MNIST(root='/content/dataset', download=True, train=True,transform=trf), batch_size=32, shuffle=False)\n",
        "    Xtrain, ytrain = extract_features(loader)\n",
        "    loader = DataLoader(MNIST(root='/content/dataset', download=True, train=False,transform=trf), batch_size=32, shuffle=False)\n",
        "    Xtest, ytest = extract_features(loader)\n",
        "    return Xtrain, ytrain, Xtest, ytest\n",
        "\n",
        "class SGDTuning():\n",
        "    def __init__(self):\n",
        "        Xtrain, ytrain, self.Xtest, self.ytest = get_data()\n",
        "        self.Xtrain,  self.Xval, self.ytrain, self.yval  = train_test_split(Xtrain, ytrain, test_size=0.33, random_state=42)\n",
        "        \n",
        "    def __call__(self, trial, params=[]):\n",
        "        if trial != None:\n",
        "            alpha = trial.suggest_float('learning_rate', 0, 1)\n",
        "            eta0 = trial.suggest_float('batch_size', 0, 10e-5)\n",
        "        else:\n",
        "            alpha, eta0 = params\n",
        "        alpha, eta0 =  np.abs(alpha), np.abs(eta0) \n",
        "        estimator = SGDClassifier(alpha=alpha,eta0=eta0, learning_rate='invscaling')\n",
        "        estimator.fit(self.Xtrain, self.ytrain)\n",
        "        pred = estimator.predict(self.Xval)\n",
        "        acc = accuracy_score(self.yval, pred)\n",
        "        return 100 * acc\n",
        "\n",
        "    def test(self, params):\n",
        "        alpha, eta0 = params\n",
        "        alpha, eta0 =  np.abs(alpha), np.abs(eta0) \n",
        "        estimator = SGDClassifier(alpha=alpha,eta0=eta0, learning_rate='invscaling')\n",
        "\n",
        "        estimator.fit(self.Xtrain,self.ytrain)\n",
        "        pred = estimator.predict(self.Xtest)\n",
        "        acc = accuracy_score(self.ytest, pred)\n",
        "        return estimator, acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Li5ufKP3wp5i"
      },
      "source": [
        "# Search the best parameters with CMA-ES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vE78nyWp1_8",
        "outputId": "cb4ee702-c424-4444-9d23-b28130b64f69"
      },
      "outputs": [],
      "source": [
        "func = SGDTuning()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FocAh_X5C_5_"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import optuna\n",
        "import gym\n",
        "import numpy as np\n",
        "\n",
        "from gym import spaces\n",
        "from bayes_opt import BayesianOptimization\n",
        "from stable_baselines3 import SAC, PPO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "u2CSBBpMz3nW"
      },
      "outputs": [],
      "source": [
        "class optimEnv(gym.Env):\n",
        "    metadata = {\"render.modes\": []}\n",
        "\n",
        "    def __init__(self, objective, render_mode=None, iterations=10, direction='maximize'):\n",
        "        super().__init__()\n",
        "\n",
        "        self.observation_space = spaces.Box(low=0.0, high=1.0, shape=(1,), dtype=np.float32)\n",
        "        self.action_space = spaces.Box(low=np.array([0, 10e-5]), high=np.array([1, 1]), dtype=np.float32)\n",
        "\n",
        "        self.objective = objective\n",
        "        self.iterations = iterations\n",
        "        self.run = []\n",
        "\n",
        "    def _get_obs(self):\n",
        "        call = self.objective(self._agent_location)\n",
        "        self.run.append(call)\n",
        "        return call\n",
        "\n",
        "    def _get_info(self):\n",
        "        return {\"current_location\" : self._agent_location}\n",
        "    \n",
        "    def reset(self):\n",
        "        self.current_step = 0\n",
        "\n",
        "        # Choose the agent's location uniformly at random\n",
        "        self._agent_location = self.action_space.sample()\n",
        "        self.last_observation = self._get_obs()\n",
        "        \n",
        "        self.max_observation = self.last_observation\n",
        "        self.max_location = self._agent_location\n",
        "\n",
        "        return self.last_observation\n",
        "\n",
        "    def step(self, action):\n",
        "        self._agent_location = action\n",
        "        # An episode is done iff current_step == iterations\n",
        "\n",
        "        observation = self._get_obs()\n",
        "        info = self._get_info()\n",
        "\n",
        "        self.current_step += 1\n",
        "        terminated = self.current_step == self.iterations\n",
        "\n",
        "        reward = observation - self.last_observation\n",
        "        if (observation > self.max_observation) :\n",
        "          self.max_observation = observation\n",
        "          self.max_location = action\n",
        "\n",
        "        print(\"Best : \", self.max_observation, \" at \", self.max_location)\n",
        "\n",
        "        return observation, reward, terminated, info\n",
        "\n",
        "    def render(self, mode=\"human\"):\n",
        "        pass\n",
        "\n",
        "    def close(self):\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# make data (#runs, #calls)\n",
        "\n",
        "# Optuna\n",
        "def get_run_optuna(study):\n",
        "\n",
        "    run = []\n",
        "    trials = study.get_trials()\n",
        "    for trial in trials:\n",
        "        value = trial.value\n",
        "        if value == None:\n",
        "            run.append(run[-1])\n",
        "        else:\n",
        "            run.append(value)\n",
        "    \n",
        "    return run\n",
        "\n",
        "# BO\n",
        "def get_run_BO(optimizer):\n",
        "    run = []\n",
        "    for res in optimizer.res:\n",
        "        run.append(res['target'])\n",
        "    print(\"run : \", run)\n",
        "    return run\n",
        "\n",
        "# RL\n",
        "def get_run_RL(env):\n",
        "    return env.run\n",
        "    \n",
        "\n",
        "# PSO\n",
        "from random import random\n",
        "from random import uniform\n",
        "\n",
        "#--- MAIN ---------------------------------------------------------------------+\n",
        "\n",
        "class Particle:\n",
        "    def __init__(self, x0):\n",
        "        self.position_i=[]          # particle position\n",
        "        self.velocity_i=[]          # particle velocity\n",
        "        self.pos_best_i=[]          # best position individual\n",
        "        self.err_best_i=-1          # best error individual\n",
        "        self.err_i=-1               # error individual\n",
        "\n",
        "        for i in range(0,num_dimensions):\n",
        "            self.velocity_i.append(uniform(-1,1))\n",
        "            self.position_i.append(x0[i])\n",
        "\n",
        "    # evaluate current fitness\n",
        "    def evaluate(self,costFunc):\n",
        "        self.err_i=costFunc(self.position_i)\n",
        "\n",
        "        # check to see if the current position is an individual best\n",
        "        if self.err_i<self.err_best_i or self.err_best_i==-1:\n",
        "            self.pos_best_i=self.position_i.copy()\n",
        "            self.err_best_i=self.err_i\n",
        "                    \n",
        "    # update new particle velocity\n",
        "    def update_velocity(self,pos_best_g):\n",
        "        w=0.5       # constant inertia weight (how much to weigh the previous velocity)\n",
        "        c1=1        # cognative constant\n",
        "        c2=2        # social constant\n",
        "        \n",
        "        for i in range(0,num_dimensions):\n",
        "            r1=random()\n",
        "            r2=random()\n",
        "            \n",
        "            vel_cognitive=c1*r1*(self.pos_best_i[i]-self.position_i[i])\n",
        "            vel_social=c2*r2*(pos_best_g[i]-self.position_i[i])\n",
        "            self.velocity_i[i]=w*self.velocity_i[i]+vel_cognitive+vel_social\n",
        "\n",
        "    # update the particle position based off new velocity updates\n",
        "    def update_position(self,bounds):\n",
        "        for i in range(0,num_dimensions):\n",
        "            self.position_i[i]=self.position_i[i]+self.velocity_i[i]\n",
        "            \n",
        "            # adjust maximum position if necessary\n",
        "            if self.position_i[i]>bounds[i][1]:\n",
        "                self.position_i[i]=bounds[i][1]\n",
        "\n",
        "            # adjust minimum position if neseccary\n",
        "            if self.position_i[i]<bounds[i][0]:\n",
        "                self.position_i[i]=bounds[i][0]\n",
        "\n",
        "def pso_run(costFunc, x0, bounds, num_particles, maxiter, verbose=False):\n",
        "    global num_dimensions\n",
        "\n",
        "    num_dimensions=len(x0)\n",
        "    err_best_g=-1                   # best error for group\n",
        "    pos_best_g=[]                   # best position for group\n",
        "\n",
        "    # establish the swarm\n",
        "    swarm=[]\n",
        "    for i in range(0,num_particles):\n",
        "        swarm.append(Particle(x0))\n",
        "\n",
        "    run = []\n",
        "\n",
        "    # begin optimization loop\n",
        "    i=0\n",
        "    while i<maxiter:\n",
        "        if verbose: print(f'iter: {i:>4d}, best solution: {err_best_g:10.6f}')\n",
        "            \n",
        "        # cycle through particles in swarm and evaluate fitness\n",
        "        for j in range(0,num_particles):\n",
        "            swarm[j].evaluate(costFunc)\n",
        "\n",
        "            run.append(-float(swarm[j].err_i))\n",
        "            print(\"run\", run)\n",
        "\n",
        "            # determine if current particle is the best (globally)\n",
        "            if swarm[j].err_i<err_best_g or err_best_g==-1:\n",
        "                pos_best_g=list(swarm[j].position_i)\n",
        "                err_best_g=float(swarm[j].err_i)\n",
        "        \n",
        "        # cycle through swarm and update velocities and position\n",
        "        for j in range(0,num_particles):\n",
        "            swarm[j].update_velocity(pos_best_g)\n",
        "            swarm[j].update_position(bounds)\n",
        "        i+=1\n",
        "\n",
        "    # print final results\n",
        "    if verbose:\n",
        "        print('\\nFINAL SOLUTION:')\n",
        "        print(f'   > {pos_best_g}')\n",
        "        print(f'   > {err_best_g}\\n')\n",
        "\n",
        "    return run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "def benchmark_optuna(n_runs, objective, sampler, name_sampler, n_calls=50) : \n",
        "    runs = []\n",
        "\n",
        "    for _ in range(n_runs) :\n",
        "        study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
        "        study.optimize(lambda t : objective(t), n_trials=n_calls, timeout=None)\n",
        "        run = get_run_optuna(study)\n",
        "        runs.append(run)\n",
        "    \n",
        "    with open(f\"{name_sampler}_runs{n_runs}_calls{n_calls}_PB1\", 'wb') as f:\n",
        "        np.save(f, np.array(runs))\n",
        "   \n",
        "    return np.array(runs)\n",
        "\n",
        "def benchmark_bo(n_runs, objective, n_calls=50):\n",
        "    runs = []\n",
        "    pbounds={'x':(0,1),'y':(10e-5,1)}\n",
        "    for _ in range(n_runs) :\n",
        "        optimizer = BayesianOptimization(f=lambda x, y : objective(None, [x, y]), pbounds=pbounds, random_state=int(time.time()))\n",
        "        optimizer.maximize(init_points=5, n_iter=45)\n",
        "        run = get_run_BO(optimizer)\n",
        "        runs.append(run)\n",
        "\n",
        "    with open(f\"BO_runs{n_runs}_calls{n_calls}_PB1\", 'wb') as f:\n",
        "        np.save(f, np.array(runs))\n",
        "\n",
        "    return np.array(runs)\n",
        "\n",
        "def benchmark_pso(n_runs, objective, n_calls=50):\n",
        "    runs = []\n",
        "    initial=[np.random.random(), np.random.random()]\n",
        "    bounds=[(0,1),(10e-5,1)]\n",
        "    for _ in range(n_runs) :\n",
        "        run = pso_run(lambda x : -objective(None, x), initial, bounds, 4, 8, False)\n",
        "        runs.append(run)\n",
        "\n",
        "    with open(f\"PSO_runs{n_runs}_calls{n_calls}_PB1\", 'wb') as f:\n",
        "        np.save(f, np.array(runs))\n",
        "\n",
        "    return np.array(runs)\n",
        "\n",
        "def benchmark_rl(n_runs, objective, n_calls=50):\n",
        "    runs = []\n",
        "    for _ in range(n_runs) :\n",
        "        env = optimEnv(lambda x : objective(None, x), iterations=4)\n",
        "        model = PPO(\"MlpPolicy\", env, verbose=1)\n",
        "        model.learn(total_timesteps=40, log_interval=4)\n",
        "        run = get_run_RL(env)\n",
        "        runs.append(run)\n",
        "\n",
        "    with open(f\"RL_runs{n_runs}_calls{n_calls}_PB1\", 'wb') as f:\n",
        "        np.save(f, np.array(runs))\n",
        "\n",
        "    return np.array(runs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "runs_RL = benchmark_rl(10, func)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
